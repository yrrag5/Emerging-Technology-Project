{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognition Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Author: Garry Cummins\n",
    " ID: G00335806"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Contents\n",
    "***\n",
    "\n",
    "**[Introduction]()**\n",
    "***\n",
    "**[Neural Network]()**\n",
    "***\n",
    "\n",
    "**[Batch, Classes, and Loading in mnist data set]()**\n",
    "***\n",
    "\n",
    "**[Setting dataset size]()**\n",
    "***\n",
    "**[Output]()**\n",
    "***\n",
    "\n",
    "**[Losses and Accuracy]()**\n",
    "***\n",
    "\n",
    "**[Running the python script on the command line ]()**\n",
    "***\n",
    "\n",
    "**[References]()**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will be going over the (digitrec.py) python script used to build a neural network using the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nerual Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To set up the neural will need to import the keras model as well as the mnist dataset, models, layers, and optimizers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports Used \n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows us to run the TensorFlow Backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch, Classes, and Loading in mnist data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "classes = 10\n",
    "# epochs used for number of instances, or life span\n",
    "epochs = 2\n",
    "\n",
    "# Takes in the mnist dataset \n",
    "(train1, train2), (testA, testB) = mnist.load_data()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Size\n",
    "train1 = train1.reshape(60000, 784)\n",
    "testA = testA.reshape(10000, 784)\n",
    "# Setting types to be displayed\n",
    "train1 = train1.astype('float32')\n",
    "testA = testA.astype('float32')\n",
    "train1 /= 255\n",
    "testA /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the mnist notebook we know that the training set contains 60000 examples while the test contains 10000. We then allocate float values to the set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 Train\n",
      "10000 Test\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Output\n",
    "print(train1.shape[0], 'Train')\n",
    "print(testA.shape[0], 'Test')\n",
    "\n",
    "train2 =  keras.utils.to_categorical(train2, classes)\n",
    "testB =  keras.utils.to_categorical(testB, classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = RMSprop(), metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pass all the params to check to see the trainable and non-trainable to pass to the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Losses and accurracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses:  2.3683375106811524\n",
      "Accuracy:  0.1081\n"
     ]
    }
   ],
   "source": [
    "# Prints out the losses and accurracy of the neural network\n",
    "result = model.evaluate(testA, testB, verbose=0)\n",
    "print('Losses: ', result[0])\n",
    "print('Accuracy: ', result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retruns the results of the loses and the accuracy of the mnist neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the python script on the command line "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After following the steps of the README, you should have python installed on your machine. Insure you are in the directory of the script file in the command line. You then use this command to run the script:\n",
    "\n",
    "python digitrec.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mnist and neural networks - https://machinelearningmastery.com/handwritten-digit-recognition-using-convolutional-neural-networks-python-keras/\n",
    "\n",
    "Tutorial - https://www.youtube.com/watch?v=Ri6LhPrJcfE\n",
    "\n",
    "Digit recognition - https://nextjournal.com/gkoehler/digit-recognition-with-keras\n",
    "\n",
    "Keras example - https://github.com/keras-team/keras/blob/master/examples/mnist_mlp.py\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
